---
name: AI PR Review

# Centralized timeout configuration
env:
  AI_EXECUTION_TIMEOUT_MINUTES: ${{ vars.AI_EXECUTION_TIMEOUT_MINUTES || '10' }}

# Triggers:
# - When a PR is first opened or moves from draft to ready for review
# - When ai-review-needed label is added to a PR
# - When someone comments "/review" on a PR
# Note: Removed 'synchronize' trigger to avoid running on every commit
# Note: Bot comments are explicitly filtered to prevent infinite loops
"on":
  pull_request:
    types: [opened, labeled]

permissions:
  contents: read
  pull-requests: write
  issues: write
  checks: read
  actions: read
  # NOTE: This workflow uses GITHUB_TOKEN for GitHub API operations
  # Uses declared permissions above for proper access control

concurrency:
  group: ai-workflows-${{ github.event.pull_request.head.ref }}
  cancel-in-progress: true

jobs:
  review:
    # Only run on PRs when opened, when ai-review-needed label is added, and not a draft, skip AI-generated branches
    if: >
      github.event_name == 'pull_request' &&
      (github.event.action == 'opened' ||
       (github.event.action == 'labeled' && github.event.label.name == 'ai-review-needed')) &&
      github.event.pull_request.draft == false &&
      !startsWith(github.head_ref, 'fix/ai-') &&
      !startsWith(github.head_ref, 'feature/ai-task-')
    runs-on: ubuntu-latest

    steps:
      - name: Get PR data when triggered by comment
        if: github.event_name == 'issue_comment'
        id: get_pr
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            const pr = await github.rest.pulls.get({
              ...context.repo,
              pull_number: context.issue.number
            });

            // Set outputs for later steps
            core.setOutput('base_ref', pr.data.base.ref);
            core.setOutput('head_ref', pr.data.head.ref);
            core.setOutput('head_sha', pr.data.head.sha);
            core.setOutput('body', pr.data.body || '');
            core.setOutput('draft', pr.data.draft);

            // Store PR data for later use
            const prData = {
              base: { ref: pr.data.base.ref },
              head: { ref: pr.data.head.ref, sha: pr.data.head.sha },
              body: pr.data.body || '',
              draft: pr.data.draft
            };

            // Export as environment variable for other steps
            core.exportVariable('PR_DATA', JSON.stringify(prData));

      - name: Check for recent AI review
        id: check_recent_review
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            // Get recent comments
            const comments = await github.rest.issues.listComments({
              ...context.repo,
              issue_number: context.issue.number,
              per_page: 100
            });

            // Check if there's a recent AI review (within last 5 minutes)
            const fiveMinutesAgo = new Date(Date.now() - 5 * 60 * 1000);
            const recentAIReview = comments.data.find(comment =>
              comment.user.login === 'github-actions[bot]' &&
              comment.body.includes('🤖 AI Review by') &&
              new Date(comment.created_at) > fiveMinutesAgo
            );

            if (recentAIReview) {
              console.log('Recent AI review found, skipping to prevent spam');
              core.setOutput('skip', 'true');
            } else {
              core.setOutput('skip', 'false');
            }

      - name: Check test status
        id: check_tests
        if: github.event_name == 'pull_request' && steps.check_recent_review.outputs.skip != 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            // Get the latest commit SHA
            const sha = context.payload.pull_request.head.sha;

            // Get all check runs for this commit
            const { data: checkRuns } = await github.rest.checks.listForRef({
              ...context.repo,
              ref: sha
            });

            // Also get workflow runs for this commit
            const { data: workflowRuns } = await github.rest.actions.listWorkflowRunsForRepo({
              ...context.repo,
              head_sha: sha
            });

            // Look for test-related workflows or checks
            const testChecks = checkRuns.check_runs.filter(check =>
              check.name.toLowerCase().includes('test') ||
              check.name.toLowerCase().includes('ci') ||
              check.name.toLowerCase().includes('build')
            );

            const testWorkflows = workflowRuns.workflow_runs.filter(run =>
              run.name.toLowerCase().includes('test') ||
              run.name.toLowerCase().includes('ci') ||
              run.name.toLowerCase().includes('build')
            );

            // Check if any tests are failing
            const failedChecks = testChecks.filter(check => check.conclusion === 'failure');
            const failedWorkflows = testWorkflows.filter(run => run.conclusion === 'failure');

            const hasFailingTests = failedChecks.length > 0 || failedWorkflows.length > 0;

            if (hasFailingTests) {
              console.log('Tests are failing. AI review will be skipped.');
              console.log('Failed checks:', failedChecks.map(c => c.name));
              console.log('Failed workflows:', failedWorkflows.map(w => w.name));

              // Create a comment explaining why review is skipped
              await github.rest.issues.createComment({
                ...context.repo,
                issue_number: context.issue.number,
                body: `## 🚨 AI Review Skipped - Tests Failing\n\n` +
                      `The AI review has been skipped because one or more tests are currently failing.\n\n` +
                      `**Failed tests:**\n` +
                      `${failedChecks.map(c => `- ${c.name}: ${c.conclusion}`).join('\n')}\n` +
                      `${failedWorkflows.map(w => `- ${w.name}: ${w.conclusion}`).join('\n')}\n\n` +
                      `Please fix the failing tests first, then the AI review will run automatically.`
              });

              core.setOutput('result', 'false');
              return false;
            }

            core.setOutput('result', 'true');
            return true;

      - name: Checkout code
        if: (steps.check_tests.outputs.result == 'true' || github.event_name != 'pull_request') && steps.check_recent_review.outputs.skip != 'true'
        uses: actions/checkout@v4
        with:
          # Fetch the PR branch - use get_pr outputs for comment triggers
          ref: ${{ github.event.pull_request.head.sha || steps.get_pr.outputs.head_sha || github.event.pull_request.head.ref || steps.get_pr.outputs.head_ref }}
          fetch-depth: 0


      - name: Debug - Check if action files exist
        if: (steps.check_tests.outputs.result == 'true' || github.event_name != 'pull_request') && steps.check_recent_review.outputs.skip != 'true'
        run: |
          echo "Checking action files..."
          ls -la ./
          ls -la ./dist/ || echo "dist folder not found"
          cat action.yml | head -10

      - name: Cache Node Modules
        if: (steps.check_tests.outputs.result == 'true' || github.event_name != 'pull_request') && steps.check_recent_review.outputs.skip != 'true'
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      - name: Build action for testing
        if: (steps.check_tests.outputs.result == 'true' || github.event_name != 'pull_request') && steps.check_recent_review.outputs.skip != 'true'
        run: |
          echo "Building action..."
          npm ci --cache ~/.npm --prefer-offline
          npm run build
          ls -la ./dist/
          echo "Testing action entry point..."
          node -e "console.log('Node.js is working')"
          echo "Checking dist/index.js..."
          head -20 ./dist/index.js

      - name: Run AI Review
        if: (steps.check_tests.outputs.result == 'true' || github.event_name != 'pull_request') && steps.check_recent_review.outputs.skip != 'true'
        id: ai_review
        continue-on-error: true
        uses: ./
        with:
          github_token: ${{ github.token }}
          openrouter_api_key: ${{ secrets.OPENROUTER_API_KEY }}
          model: ${{ vars.AI_MODEL || 'google/gemini-2.5-pro' }}
          review_type: 'full'
          exclude_patterns: 'package-lock.json,*.lock'
          request_timeout_seconds: 600
          max_tokens: 32768
          temperature: 0.7
          retries: 3

      - name: Debug - Check action step result
        if: (steps.check_tests.outputs.result == 'true' || github.event_name != 'pull_request') && steps.check_recent_review.outputs.skip != 'true'
        run: |
          echo "AI Review Step Result:"
          echo "outcome: ${{ steps.ai_review.outcome }}"
          echo "conclusion: ${{ steps.ai_review.conclusion }}"

      - name: Debug - Check AI Review outputs
        if: (steps.check_tests.outputs.result == 'true' || github.event_name != 'pull_request') && steps.check_recent_review.outputs.skip != 'true'
        run: |
          echo "AI Review Step Outputs:"
          echo "review_status: ${{ steps.ai_review.outputs.review_status }}"
          echo "review_comment length: ${#REVIEW_COMMENT}"
          echo "Conditions check:"
          echo "check_tests result: ${{ steps.check_tests.outputs.result }}"
          echo "recent_review skip: ${{ steps.check_recent_review.outputs.skip }}"
          echo "ai_review status: ${{ steps.ai_review.outputs.review_status }}"
        env:
          REVIEW_COMMENT: ${{ steps.ai_review.outputs.review_comment }}

      - name: Post review comment
        if: (steps.check_tests.outputs.result == 'true' || github.event_name != 'pull_request') && steps.check_recent_review.outputs.skip != 'true' && steps.ai_review.outputs.review_status == 'success'
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            const review = process.env.REVIEW_CONTENT;
            const model = process.env.AI_MODEL || 'google/gemini-2.5-pro';
            const currentDate = new Date().toISOString().split('T')[0]; // YYYY-MM-DD format
            const currentTime = new Date().toLocaleTimeString('en-US', {
              timeZone: 'UTC',
              hour12: false,
              hour: '2-digit',
              minute: '2-digit'
            });

            console.log('Post review comment step executing...');
            console.log('Review content length:', review ? review.length : 0);
            console.log('Review preview:', review ? review.substring(0, 100) : 'No content');

            if (!review || review.trim() === '') {
              console.log('No review content to post - review is empty');
              return;
            }

            // Extract model name for header (e.g., "gemini-2.5-pro" from "google/gemini-2.5-pro")
            const modelDisplayName = model.includes('/') ? model.split('/')[1] : model;
            const modelHeader = modelDisplayName.charAt(0).toUpperCase() + modelDisplayName.slice(1).replace(/-/g, ' ');

            // GitHub comment limit is ~65,536 characters, but let's be conservative
            const maxCommentLength = 60000;
            const footerText = `\n\n---\n*This review was automatically generated by \`${model}\` via OpenRouter on ${currentDate} at ${currentTime} UTC. Please consider it as supplementary feedback alongside human review.*`;

            let reviewContent = review;
            const headerText = `## 🤖 AI Review by ${modelHeader}\n\n`;
            const totalCommentLength = headerText.length + reviewContent.length + footerText.length;

            if (totalCommentLength > maxCommentLength) {
              console.log(`Review content too long (${totalCommentLength} chars). Truncating to fit within ${maxCommentLength} chars.`);
              const availableLength = maxCommentLength - headerText.length - footerText.length - 100; // Extra buffer
              const truncationMessage = '\n\n**[Review truncated due to length limits. See full review in action logs.]**';
              reviewContent = review.substring(0, availableLength - truncationMessage.length) + truncationMessage;
            }

            const comment = `${headerText}${reviewContent}${footerText}`;

            console.log(`Final comment length: ${comment.length} chars`);
            console.log(`Model header: ${modelHeader}`);
            console.log('Posting comment to PR...');

            // For PR events
            if (context.eventName === 'pull_request') {
              await github.rest.issues.createComment({
                ...context.repo,
                issue_number: context.issue.number,
                body: comment
              });
              console.log('Comment posted successfully');
            }
            // For issue comments on PRs (when /review is used)
            else if (context.eventName === 'issue_comment') {
              await github.rest.issues.createComment({
                ...context.repo,
                issue_number: context.issue.number,
                body: comment
              });
              console.log('Comment posted successfully');
            }
        env:
          REVIEW_CONTENT: ${{ steps.ai_review.outputs.review_comment }}
          AI_MODEL: ${{ vars.AI_MODEL }}

      - name: Handle AI review failure
        if: steps.ai_review.outputs.review_status == 'failure' || steps.ai_review.outputs.review_status == 'error'
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            // Safely add failure label with auto-creation
            try {
              console.log('Adding ai-review-failed label...');

              // Check if label exists, create if missing
              try {
                await github.rest.issues.getLabel({
                  ...context.repo,
                  name: 'ai-review-failed'
                });
                console.log('ai-review-failed label already exists');
              } catch (labelError) {
                if (labelError.status === 404) {
                  console.log('Creating ai-review-failed label...');
                  await github.rest.issues.createLabel({
                    ...context.repo,
                    name: 'ai-review-failed',
                    color: 'D93F0B',
                    description: 'AI review failed - manual review needed'
                  });
                  console.log('✓ Created ai-review-failed label');
                }
              }

              // Add the label to the PR/issue
              await github.rest.issues.addLabels({
                ...context.repo,
                issue_number: context.issue.number,
                labels: ['ai-review-failed']
              });
              console.log('✓ Added ai-review-failed label to PR');
            } catch (error) {
              console.log(`⚠ Failed to add ai-review-failed label: ${error.message}`);
            }

            // Post a comment about the failure
            const failureComment = `## ⚠️ AI Review Failed\n\nThe AI review could not be completed. This could be due to:\n- API rate limiting\n- Large diff size\n- Temporary service issues\n\nPlease retry the review later or request manual review.`;

            try {
              await github.rest.issues.createComment({
                ...context.repo,
                issue_number: context.issue.number,
                body: failureComment
              });
              console.log('✓ Posted failure comment');
            } catch (error) {
              console.log(`⚠ Failed to post failure comment: ${error.message}`);
            }

            // Fail the workflow step to indicate the review failure
            core.setFailed('AI review failed - manual review needed');

      - name: Add labels based on review
        if: >
          github.event_name == 'pull_request' &&
          steps.check_tests.outputs.result == 'true' &&
          steps.check_recent_review.outputs.skip != 'true' &&
          steps.ai_review.outputs.review_status == 'success'
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            const review = (process.env.REVIEW_CONTENT || '').toLowerCase();

            // Helper function to safely add labels with auto-creation
            const safeAddLabels = async (labelsToAdd) => {
              if (labelsToAdd.length === 0) return;

              console.log(`Attempting to add labels: ${labelsToAdd.join(', ')}`);

              // First, get existing repository labels
              let existingLabels;
              try {
                const { data } = await github.rest.issues.listLabelsForRepo({
                  ...context.repo,
                  per_page: 100
                });
                existingLabels = new Set(data.map(label => label.name));
                console.log(`Repository has ${existingLabels.size} existing labels`);
              } catch (error) {
                console.log(`Warning: Could not fetch existing labels: ${error.message}`);
                existingLabels = new Set();
              }

              // Create missing labels with appropriate colors and descriptions
              const labelDefinitions = {
                'security-review-needed': { color: 'E99695', description: 'Requires security review' },
                'performance-impact': { color: 'F9D71C', description: 'May impact performance' },
                'breaking-change': { color: 'B60205', description: 'Breaking API changes' },
                'needs-docs': { color: 'BFD4F2', description: 'Documentation updates needed' },
                'ai-reviewed': { color: '9F4F96', description: 'Reviewed by AI PR review system' }
              };

              for (const labelName of labelsToAdd) {
                if (!existingLabels.has(labelName)) {
                  console.log(`Creating missing label: ${labelName}`);
                  try {
                    const labelDef = labelDefinitions[labelName] || { color: 'CCCCCC', description: 'Auto-created by AI workflow' };
                    await github.rest.issues.createLabel({
                      ...context.repo,
                      name: labelName,
                      color: labelDef.color,
                      description: labelDef.description
                    });
                    console.log(`✓ Created label: ${labelName}`);
                    existingLabels.add(labelName); // Add to set for subsequent iterations
                  } catch (error) {
                    console.log(`⚠ Failed to create label ${labelName}: ${error.message}`);
                  }
                }
              }

              // Now add all labels to the issue/PR
              try {
                await github.rest.issues.addLabels({
                  ...context.repo,
                  issue_number: context.issue.number,
                  labels: labelsToAdd
                });
                console.log(`✓ Successfully added labels: ${labelsToAdd.join(', ')}`);
              } catch (error) {
                console.log(`⚠ Failed to add some labels: ${error.message}`);
                // Try adding labels one by one if bulk add fails
                for (const labelName of labelsToAdd) {
                  try {
                    await github.rest.issues.addLabels({
                      ...context.repo,
                      issue_number: context.issue.number,
                      labels: [labelName]
                    });
                    console.log(`✓ Added label individually: ${labelName}`);
                  } catch (individualError) {
                    console.log(`⚠ Failed to add individual label ${labelName}: ${individualError.message}`);
                  }
                }
              }
            };

            const labels = [];

            // Helper function to check if a phrase indicates actual concern vs no concern
            const hasActualConcern = (text, keywords) => {
              for (const keyword of keywords) {
                const regex = new RegExp(`(no|zero|minimal|none|without|negligible)\\s+${keyword}`, 'i');
                if (regex.test(text)) {
                  // Found negation before the keyword, so no actual concern
                  return false;
                }
                if (text.includes(keyword)) {
                  // Found keyword without negation
                  return true;
                }
              }
              return false;
            };

            // Add labels based on review content (avoid triggering AI fix workflows)
            if (hasActualConcern(review, ['security concern', 'security issue', 'security vulnerability', 'security risk'])) {
              labels.push('security-review-needed');
            }
            if (hasActualConcern(review, ['performance impact', 'performance implication', 'performance degradation', 'performance issue'])) {
              labels.push('performance-impact');
            }
            if (hasActualConcern(review, ['breaking change', 'backward incompatible', 'backwards incompatible'])) {
              labels.push('breaking-change');
            }
            if (review.includes('needs documentation') || review.includes('documentation needed') || review.includes('missing documentation')) {
              labels.push('needs-docs');
            }

            labels.push('ai-reviewed');

            // Filter out any labels that could trigger AI fix workflows to prevent loops
            const filteredLabels = labels.filter(label =>
              !label.startsWith('ai-fix-') &&
              label !== 'ai-fix-lint' &&
              label !== 'ai-fix-security' &&
              label !== 'ai-fix-tests'
            );

            // Use the safe label adding function
            await safeAddLabels(filteredLabels);
        env:
          REVIEW_CONTENT: ${{ steps.ai_review.outputs.review_comment }}

      - name: Remove ai-review-needed label
        if: >
          github.event.action == 'labeled' &&
          github.event.label.name == 'ai-review-needed' &&
          steps.check_tests.outputs.result == 'true' &&
          steps.check_recent_review.outputs.skip != 'true' &&
          steps.ai_review.outputs.review_status == 'success'
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            await github.rest.issues.removeLabel({
              ...context.repo,
              issue_number: context.issue.number,
              name: 'ai-review-needed'
            });
